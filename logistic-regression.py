# -*- coding: utf-8 -*-
"""21l5640ab13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10tSS2ysBhVQ9Mb4zs6-k77RWyE5La-RE
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import accuracy_score

iris = pd.read_csv("/content/Iris.csv")
print(iris.isna().sum())
iris.fillna(iris.mean(), inplace=True)

fig, axes = plt.subplots(2, 2, figsize=(12, 8))
for i in range(2):
    for j in range(2):
        axes[i, j].boxplot(iris[iris.columns[i * 2 + j]])
        axes[i, j].set_title(iris.columns[i * 2 + j])

# Remove outliers
for i in range(2):
    iris[iris.columns[i]] = np.where(iris[iris.columns[i]] < iris[iris.columns[i]].quantile(0.05),
                                       iris[iris.columns[i]].quantile(0.05),
                                       iris[iris.columns[i]].quantile(0.95))

correlation = iris.corr()
print(correlation)
iris = iris.drop("SepalWidthCm", axis=1)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(iris.drop("Species", axis=1), iris["Species"], test_size=0.2)

# One-hot encoder
encoder = OneHotEncoder(sparse=False)
y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))
y_test_encoded = encoder.transform(y_test.values.reshape(-1, 1))

# logistic regression
model = LogisticRegression(multi_class="ovr")
model.fit(X_train, y_train)

predictions = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, predictions))
print("R-squared:", model.score(X_test, y_test))
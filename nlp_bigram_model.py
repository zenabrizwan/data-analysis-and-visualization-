# -*- coding: utf-8 -*-
"""Bigram.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FIRcOazv-rbywn412JG3ZnP-pfyx5bgh
"""

import re
from pathlib import Path
import string
from functools import reduce
from math import log
import itertools

# Enter smoothing or no smoothing.
smoothing = 1
filename = "textfile.txt"

# Loads file
# input - filename.txt
# returns a list of sentences seperated by newline in the textfile.
def load_file(filename):
    ### Write your Code here

   with open(filename, 'r') as f:
      lines=f.readlines()

   sentences=[]
   for line in lines:
       sentences.extend(lines.split("\n"))
       lines=[sentence for sentence in sentences if sentence]

   return lines

# Tokenizes the sentences meaning split the sentences into words seperated by the "white sapce".
# input - List of sentences
# returns a list of lists of each sentence being tokenized.
def tokenize_sentence(lines):
    ### Write your Code here

  tokenized_sentences = []
  for line in lines:
    # Split the line into words, removing punctuation and whitespace
    tokens = re.split(r'\W+', line)

    # Add the tokens to the list of tokenized sentences
    tokenized_sentences.append(tokens)

  return tokenized_sentences

# Prepare the data for training the bigram model.
# remove punctuations -print(string.punctuation) ---- !"#$%&'()*+,-./:;<=>?@[\]^_`{|}~ ----
# remove empty strings.
# lower case all the words
# add <s> at the beginning and </s> at the end of every sentence in the corpus.
# input - list of lists of words obtained from "tokenize_sentence" function.
# returns - list of lists
def prep_data(lines):
    ### Write your Code here # remove punctuations
        # removes empty strings
        # lower case
        # Append </s> at the end of each sentence in the corpus
        # Append <s> at the beginning of each sentence in the corpus

        import string

def prep_data(lines):
  """Prepare the data for training the bigram model.
  input - list of lists of words obtained from "tokenize_sentence" function.
  returns - list of lists
  """

  # Remove punctuation
  for sentence in lines:
    sentence = [token for token in sentence if token not in string.punctuation]

  # Remove empty strings
  lines = [sentence for sentence in lines if sentence]

  # Lower case all the words
  for sentence in lines:
    sentence = [token.lower() for token in sentence]

  # Append </s> at the end of each sentence in the corpus
  for sentence in lines:
    sentence.append("</s>")

  # Append <s> at the beginning of each sentence in the corpus
  for sentence in lines:
    sentence.insert(0, "<s>")

  print("No of sentences in Corpus: "+str(len(lines)))

  return lines

dataset = load_file(filename)
dataset = tokenize_sentence(dataset)
dataset = prep_data(dataset)

# Creates the vocabulary file of the dataset.
def vocabulary(dataset):
    dataset_vocab = set(itertools.chain.from_iterable(dataset))
    # remove <s> and </s> from the vocabulary of the dataset
    dataset_vocab.remove('<s>')
    dataset_vocab.remove('</s>')
    dataset_vocab = list(dataset_vocab)
    dataset_vocab.append('<s>')
    dataset_vocab.append('</s>')
    return dataset_vocab

dataset_vocab = vocabulary(dataset)

len(dataset_vocab)

# Counts the no. of times a word repeats (frequency of each word) in the corpus.
# input - list of lists of words obtained from "prep_data"
# returns - a dictionary defined as {word:frequency} for words of the corpus including <s> and </s>.
def freq_of_unique_words(lines):
   ### Write your Code here
    print("No of unique words in corpus : "+ str(unique_word_count))
    return count

unique_word_frequency = freq_of_unique_words(dataset)
#len(unique_word_frequency)

"""QUESTION 1A (5)"""

# Computes the bigram frequncies
# Bigram frequncies means the number of times a word appears after a given word in the corpus.
# inputs:
# lines - list of lists obtained from "prep_data".
# count - dictionary obtained from "freq_of_unique_words".
# returns - dictionary of bigram frequencies {(word|given word): count(word|given word)} --- count(word|given word)~int.
def compute_bigram_frequencies(lines):
   ### Write your Code here

    #The number of bigram_frquencies in the corpus
    #print(len(bigram_frequencies))
    return bigram_frequencies

bigram_frequencies = compute_bigram_frequencies(dataset)
#print(bigram_frequencies)
bigram_unique_word_count = len(unique_word_frequency)
# print("\n"+"No of words in bigram: "+str(bigram_unique_word_count))

"""QUESTION 1B (5)"""

# Calculating bigram probability
# bigram probability means P(word|given word) = count(word|given word)/ count(given word).
# if count(word|given word) or count(given word) is 0 then probability is 0.
# input bigram_frquencies and count obtained from "freq_of_unique_words".
# returns dictionary of bigram probabilities {(word|given word): probabilty} --- probability is a float value.
def compute_bigram_probabilities(bigram_frequencies,count):
  ### Write your Code here
    return bigram_probabilities

bigram_probabilities = compute_bigram_probabilities(bigram_frequencies,unique_word_frequency)
#bigram_probabilities

# Bigram frequncies of the test sentence computed using the bigram frequencies of the training data.
# add-one smoothing if 1, no smoothing if 0 ----- smoothing
def compute_bigram_count_test_sentence(given_word,word,smoothing):
    if smoothing==0:
        return 0 if bigram_frequencies.get((given_word,word))==None else bigram_frequencies.get((given_word,word))
    elif smoothing == 1:
        return 1 if bigram_frequencies.get((given_word,word))==None else bigram_frequencies.get((given_word,word))+1

# A table showing the bigram counts for test sentence.
def print_bigram_freq_test_sentence(test_sentence_vocab,smoothing):
    print("A table showing the bigram counts for test sentence."+"\nsmoothing ="+str(smoothing))
    print("\t\t\t", end="")
    for word in test_sentence_vocab:
        if word != '<s>':
            print(word, end="\t\t")
    print("")
    for given_word in test_sentence_vocab:
        if given_word != '</s>':
            if(smoothing==1):
                print(unique_word_frequency.get(given_word)+bigram_unique_word_count, end ="\t")
            elif(smoothing==0):
                print(unique_word_frequency.get(given_word), end ="\t")
            print(given_word, end="\t\t")
            for word in test_sentence_vocab:
                if word !='<s>':
                    print("{0:}".format(compute_bigram_count_test_sentence(given_word,word,smoothing)), end="\t\t")
            print("")
    print("")

# Bigram probabilities of the test sentence computed using the bigram probabilities of the training data.
# add-one smoothing if 1, no smoothing if 0 ---- smoothing
def compute_bigram_prob_test_sentence(given_word,word,smoothing):
    bigram_freq = 0 if bigram_frequencies.get((given_word,word))==None else bigram_frequencies.get((given_word,word))
    uni_freq = 0 if unique_word_frequency.get((given_word))==None else unique_word_frequency.get((given_word))
    if smoothing==0:
        return 0 if bigram_probabilities.get((given_word,word))==None else bigram_probabilities.get((given_word,word))
    elif smoothing == 1:
        numerator = bigram_freq+1
        denominator = uni_freq+bigram_unique_word_count
        return 0.0 if numerator == 0 or denominator == 0 else float(numerator) / float(denominator)

"""QUESTION 1C (5)"""

# A table showing the bigram probabilities for test sentence.
def print_bigram_probabilities_test_sentence(test_sentence_vocab,smoothing):
   ### Write your Code here

# Print the probability of the test sentence
# for add-one smoothing if 1, no smoothing if 0
def compute_prob_test_sentence(sentence,smoothing):
   ### Write your Code here

# Test sentence here
test_sentences = [['upon this the captain started , and eagerly desired to know more .'],['thus , because no man can follow another into these halls .']]

for i in range (len(test_sentences)):
    test_sentence = test_sentences[i]
    print("!!!!!!!!!!The test Sentence is!!!!!!!!!!")
    print(test_sentence)
    test_sentence = tokenize_sentence(test_sentence)
    test_sentence = prep_data(test_sentence)

    # Vocabulary of test sentence
    test_sentence_vocab = vocabulary(test_sentence)

    test_sentence = list(itertools.chain.from_iterable(test_sentence))
    #test_sentence

    # A table showing the bigram counts for test sentence.
    print_bigram_freq_test_sentence(test_sentence_vocab,smoothing)

    # A table showing the bigram probabilities for test sentence.
    print_bigram_probabilities_test_sentence(test_sentence_vocab,smoothing)

    # The probability of the sentence under the trained model
    print("The probability of the sentence under the trained model"+"\nsmoothing ="+str(smoothing))
    print(compute_prob_test_sentence(test_sentence,0))